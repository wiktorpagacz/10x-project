# Plan Test√≥w - Aplikacja do Generowania Fiszek z Wykorzystaniem AI

## 1. Wprowadzenie i Cele Testowania

### 1.1 Cel dokumentu
Niniejszy dokument definiuje kompleksowƒÖ strategiƒô testowania aplikacji do generowania fiszek edukacyjnych z u≈ºyciem sztucznej inteligencji. Celem test√≥w jest zapewnienie wysokiej jako≈õci, bezpiecze≈Ñstwa i niezawodno≈õci systemu przed wdro≈ºeniem produkcyjnym.

### 1.2 Cele testowania
- **Weryfikacja funkcjonalno≈õci**: Potwierdzenie, ≈ºe wszystkie funkcje dzia≈ÇajƒÖ zgodnie z wymaganiami
- **Zapewnienie jako≈õci kodu**: Wykrycie b≈Çƒôd√≥w logicznych, problem√≥w z obs≈ÇugƒÖ wyjƒÖtk√≥w i edge cases
- **Bezpiecze≈Ñstwo**: Walidacja mechanizm√≥w autoryzacji, autentykacji i ochrony danych u≈ºytkownika
- **Wydajno≈õƒá**: Potwierdzenie, ≈ºe system obs≈Çuguje zak≈Çadane obciƒÖ≈ºenie i spe≈Çnia wymagania czasowe
- **Kompatybilno≈õƒá**: Sprawdzenie poprawno≈õci dzia≈Çania w r√≥≈ºnych ≈õrodowiskach i przeglƒÖdarkach
- **Do≈õwiadczenie u≈ºytkownika**: Walidacja responsywno≈õci, dostƒôpno≈õci (a11y) i intuicyjno≈õci interfejsu

### 1.3 Zakres projektu
Aplikacja webowa do generowania fiszek edukacyjnych z tekstu ≈∫r√≥d≈Çowego z wykorzystaniem modeli AI. System umo≈ºliwia:
- Rejestracjƒô i autentykacjƒô u≈ºytkownik√≥w
- Generowanie fiszek z tekstu (1000-10000 znak√≥w) przy u≈ºyciu API OpenRouter
- ZarzƒÖdzanie kolekcjƒÖ fiszek (CRUD operations)
- System powt√≥rek oparty na algorytmie spaced repetition
- Pe≈Çnotekstowe wyszukiwanie w fiszkach

## 2. Zakres Test√≥w

### 2.1 Funkcjonalno≈õci objƒôte testami

#### 2.1.1 Modu≈Ç Autentykacji i Autoryzacji
- Rejestracja nowych u≈ºytkownik√≥w
- Logowanie u≈ºytkownik√≥w (email + has≈Ço)
- Wylogowanie u≈ºytkownik√≥w
- Odzyskiwanie has≈Ça
- Weryfikacja sesji u≈ºytkownika
- Row-Level Security (RLS) w bazie danych

#### 2.1.2 Modu≈Ç Generowania Fiszek
- Walidacja d≈Çugo≈õci tekstu ≈∫r√≥d≈Çowego (1000-10000 znak√≥w)
- Integracja z OpenRouter API
- Hashowanie tekstu ≈∫r√≥d≈Çowego (SHA-256) do deduplikacji
- Obs≈Çuga b≈Çƒôd√≥w API (timeout, rate limiting, b≈Çƒôdy modelu)
- Mechanizm retry z exponential backoff
- Zapisywanie log√≥w b≈Çƒôd√≥w generacji
- Tryb mock dla rozwoju i testowania

#### 2.1.3 Modu≈Ç ZarzƒÖdzania Fiszkami
- Tworzenie fiszek (pojedynczo i wsadowo)
- Pobieranie listy fiszek z paginacjƒÖ
- Pobieranie szczeg√≥≈Ç√≥w pojedynczej fiszki
- Aktualizacja fiszek
- Usuwanie fiszek
- Pe≈Çnotekstowe wyszukiwanie (FTS)
- ≈öledzenie ≈∫r√≥d≈Ça fiszki (manual, ai-full, ai-edited)

#### 2.1.4 Modu≈Ç Systemu Powt√≥rek
- Pobieranie fiszek do powt√≥rki (spaced repetition)
- Algorytm ustalania kolejnej daty powt√≥rki
- Losowanie kolejno≈õci prezentacji fiszek
- ≈öledzenie postƒôp√≥w w nauce

### 2.2 Funkcjonalno≈õci wy≈ÇƒÖczone z test√≥w
- Hosting i deployment infrastructure (DigitalOcean)
- Konfiguracja CI/CD pipeline (GitHub Actions) - testowany oddzielnie
- Wewnƒôtrzne mechanizmy Supabase Auth (zak≈Çadamy poprawno≈õƒá dzia≈Çania jako managed service)

### 2.3 Kryteria wej≈õcia
- Kompletny kod ≈∫r√≥d≈Çowy dostƒôpny w repozytorium
- Dzia≈ÇajƒÖce ≈õrodowisko deweloperskie
- Dostƒôp do instancji Supabase (lokalna lub dev)
- Klucz API OpenRouter (lub w≈ÇƒÖczony tryb mock)
- Dokumentacja techniczna i diagramy architektury
- Zdefiniowane wymagania funkcjonalne i niefunkcjonalne

### 2.4 Kryteria wyj≈õcia
- 100% pokrycia testami jednostkowymi dla serwis√≥w i funkcji utility
- 90% pokrycia testami integracyjnymi dla endpoint√≥w API
- Wszystkie testy end-to-end dla critical path przeprowadzone i przesz≈Çy pomy≈õlnie
- Zero b≈Çƒôd√≥w krytycznych (blocker/critical)
- Maksymalnie 5 b≈Çƒôd√≥w o ≈õrednim priorytecie
- Wszystkie b≈Çƒôdy dokumentowane w systemie zg≈Çaszania
- Testy wydajno≈õciowe potwierdzone z wynikami w granicach SLA
- Testy bezpiecze≈Ñstwa przeprowadzone bez wykrytych luk krytycznych

## 3. Typy Test√≥w do Przeprowadzenia

### 3.1 Testy Jednostkowe (Unit Tests)

#### 3.1.1 Zakres
Testy izolowanych funkcji, klas i komponent√≥w bez zale≈ºno≈õci zewnƒôtrznych.

#### 3.1.2 Priorytety
- **Priorytet 1 (Krytyczny)**:
  - Funkcje serwisowe w `src/lib/services/`:
    - `flashcard.service.ts` - getFlashcards, createFlashcard, batchCreateFlashcards
    - `generation.service.ts` - generateFlashcardsFromText, obs≈Çuga b≈Çƒôd√≥w
    - `review.service.ts` - getFlashcardsDueForReview, algorytm shuffling
    - `openrouter.service.ts` - komunikacja z API, parsowanie odpowiedzi
  - Funkcje utility:
    - `crypto.ts` - sha256 hashing
    - `utils.ts` - funkcje pomocnicze (cn, formatDate, etc.)
  - Hooki React w `src/components/*/hooks/`:
    - `useGenerationViewState.ts` - state machine generacji
    - `useLoginForm.ts`, `useRegisterForm.ts` - walidacja formularzy
    - `useCharacterCounter.ts` - logika liczenia znak√≥w

- **Priorytet 2 (Wysoki)**:
  - Komponenty UI bez side effects:
    - `ProgressBar.tsx`, `CharacterCounter.tsx`
    - Komponenty shadcn/ui (je≈õli zmodyfikowane)
  - Walidacja Zod schemas w endpointach API

#### 3.1.3 Techniki testowania
- **Mocking**: Mock zewnƒôtrznych zale≈ºno≈õci (Supabase client, fetch API)
- **Stubbing**: Stub odpowiedzi z API
- **Spy functions**: ≈öledzenie wywo≈Ça≈Ñ funkcji
- **Parametrized tests**: Testy z wieloma zestawami danych wej≈õciowych
- **Edge cases**: Puste stringi, warto≈õci null/undefined, warto≈õci graniczne

#### 3.1.4 Przyk≈Çadowe scenariusze testowe

**TS-UNIT-001: Walidacja d≈Çugo≈õci tekstu w generateFlashcardsFromText**
- **Kroki**:
  1. Wywo≈Çaj funkcjƒô z tekstem < 1000 znak√≥w
  2. Wywo≈Çaj funkcjƒô z tekstem = 1000 znak√≥w
  3. Wywo≈Çaj funkcjƒô z tekstem = 10000 znak√≥w
  4. Wywo≈Çaj funkcjƒô z tekstem > 10000 znak√≥w
- **Oczekiwany rezultat**:
  - Przypadek 1: Rzuƒá b≈ÇƒÖd walidacji
  - Przypadek 2, 3: Sukces
  - Przypadek 4: Rzuƒá b≈ÇƒÖd walidacji

**TS-UNIT-002: SHA-256 hashing jest deterministyczny**
- **Kroki**:
  1. Wywo≈Çaj sha256() z tym samym tekstem 100 razy
- **Oczekiwany rezultat**: Wszystkie hashe sƒÖ identyczne

**TS-UNIT-003: getFlashcards - paginacja**
- **Kroki**:
  1. Mock 50 fiszek w bazie
  2. Pobierz stronƒô 1, pageSize=20
  3. Pobierz stronƒô 2, pageSize=20
  4. Pobierz stronƒô 3, pageSize=20
- **Oczekiwany rezultat**:
  - Strona 1: 20 fiszek, totalPages=3
  - Strona 2: 20 fiszek, totalPages=3
  - Strona 3: 10 fiszek, totalPages=3

**TS-UNIT-004: useGenerationViewState - state machine**
- **Kroki**:
  1. Stan poczƒÖtkowy: 'idle'
  2. Wywo≈Çaj startGeneration()
  3. Wywo≈Çaj completeGeneration()
  4. Wywo≈Çaj startGeneration() ponownie
  5. Wywo≈Çaj setGenerationError()
  6. Wywo≈Çaj retryGeneration()
- **Oczekiwany rezultat**:
  - Krok 1: status='idle'
  - Krok 2: status='generating'
  - Krok 3: status='reviewing'
  - Krok 4: B≈ÇƒÖd (nie mo≈ºna generowaƒá podczas reviewing)
  - Krok 5: status='error'
  - Krok 6: status='generating', retryCount=1

**TS-UNIT-005: Fisher-Yates shuffle nie zmienia d≈Çugo≈õci ani element√≥w**
- **Kroki**:
  1. Stw√≥rz tablicƒô 100 unikalnych element√≥w
  2. Wywo≈Çaj shuffleArray()
  3. Por√≥wnaj d≈Çugo≈õci i zawarto≈õƒá (set)
- **Oczekiwany rezultat**:
  - D≈Çugo≈õƒá niezmieniona
  - Wszystkie elementy obecne (zbi√≥r przed == zbi√≥r po)
  - Kolejno≈õƒá r√≥≈ºna (z prawdopodobie≈Ñstwem ~100%)

### 3.2 Testy Integracyjne (Integration Tests)

#### 3.2.1 Zakres
Testy integracji miƒôdzy komponentami, szczeg√≥lnie API endpoints z serwisami i bazƒÖ danych.

#### 3.2.2 Priorytety
- **Priorytet 1 (Krytyczny)**:
  - Endpointy autentykacji:
    - POST /api/auth/login
    - POST /api/auth/register
    - POST /api/auth/logout
  - Endpointy generacji:
    - POST /api/generations (z mockiem OpenRouter)
  - Endpointy fiszek:
    - GET /api/flashcards (z paginacjƒÖ i wyszukiwaniem)
    - POST /api/flashcards
    - POST /api/flashcards/batch
    - GET /api/flashcards/[id]
    - PUT /api/flashcards/[id]
    - DELETE /api/flashcards/[id]
  - Endpointy powt√≥rek:
    - GET /api/reviews

- **Priorytet 2 (Wysoki)**:
  - Middleware (autentykacja, rate limiting)
  - Integracja z Supabase (operacje CRUD)
  - Full-text search w PostgreSQL

#### 3.2.3 Techniki testowania
- **Test database**: Osobna instancja bazy danych dla test√≥w
- **Database seeding**: Przygotowanie danych testowych
- **Transaction rollback**: Rollback po ka≈ºdym te≈õcie dla izolacji
- **API testing**: Symulacja request√≥w HTTP
- **Mock external services**: Mock OpenRouter API

#### 3.2.4 Przyk≈Çadowe scenariusze testowe

**TS-INT-001: POST /api/auth/register - pomy≈õlna rejestracja**
- **Warunki wstƒôpne**: Baza danych pusta
- **Kroki**:
  1. Wy≈õlij POST /api/auth/register z poprawnym email i has≈Çem (min 6 znak√≥w)
  2. Sprawd≈∫ response status
  3. Sprawd≈∫ bazƒô danych Supabase Auth
- **Oczekiwany rezultat**:
  - Status 200
  - Zwr√≥cony user object z id i email
  - U≈ºytkownik utworzony w auth.users

**TS-INT-002: POST /api/auth/register - duplikat email**
- **Warunki wstƒôpne**: U≈ºytkownik test@example.com istnieje
- **Kroki**:
  1. Wy≈õlij POST /api/auth/register z email test@example.com
- **Oczekiwany rezultat**:
  - Status 400
  - Kod b≈Çƒôdu: USER_ALREADY_EXISTS

**TS-INT-003: POST /api/auth/login - poprawne dane**
- **Warunki wstƒôpne**: U≈ºytkownik test@example.com z has≈Çem "password123" istnieje
- **Kroki**:
  1. Wy≈õlij POST /api/auth/login z poprawnymi danymi
  2. Sprawd≈∫ response
  3. Sprawd≈∫ cookies/session
- **Oczekiwany rezultat**:
  - Status 200
  - Zwr√≥cony user object
  - Session cookie ustawiony

**TS-INT-004: POST /api/auth/login - niepoprawne has≈Ço**
- **Warunki wstƒôpne**: U≈ºytkownik test@example.com istnieje
- **Kroki**:
  1. Wy≈õlij POST /api/auth/login z niepoprawnym has≈Çem
- **Oczekiwany rezultat**:
  - Status 401
  - Komunikat: "Invalid credentials"

**TS-INT-005: POST /api/generations - generacja z mockiem**
- **Warunki wstƒôpne**:
  - U≈ºytkownik zalogowany
  - OpenRouter API zmockowany (zwraca 5 fiszek)
- **Kroki**:
  1. Wy≈õlij POST /api/generations z tekstem 2000 znak√≥w
  2. Sprawd≈∫ response
  3. Sprawd≈∫ bazƒô danych (tabela generations i flashcards)
- **Oczekiwany rezultat**:
  - Status 200
  - generation_id i suggested_flashcards w response
  - Rekord w generations z source_text_hash
  - 5 sugerowanych fiszek w response

**TS-INT-006: POST /api/generations - rate limiting**
- **Warunki wstƒôpne**: U≈ºytkownik zalogowany
- **Kroki**:
  1. Wy≈õlij 5 request√≥w POST /api/generations w ciƒÖgu 30 sekund
  2. Wy≈õlij 6. request
- **Oczekiwany rezultat**:
  - Requesty 1-5: Status 200
  - Request 6: Status 429 (Too Many Requests)
  - Komunikat: "Maximum 5 requests per minute allowed"

**TS-INT-007: GET /api/flashcards - paginacja i wyszukiwanie**
- **Warunki wstƒôpne**:
  - U≈ºytkownik zalogowany
  - 50 fiszek w bazie (25 o tematyce "historia", 25 o tematyce "biologia")
- **Kroki**:
  1. GET /api/flashcards?page=1&pageSize=20
  2. GET /api/flashcards?page=2&pageSize=20
  3. GET /api/flashcards?search=historia&page=1&pageSize=20
- **Oczekiwany rezultat**:
  - Request 1: 20 fiszek, totalPages=3
  - Request 2: 20 fiszek, totalPages=3
  - Request 3: ~25 fiszek (wszystkie z "historia" w tek≈õcie), poprawny totalPages

**TS-INT-008: POST /api/flashcards/batch - zapis wsadowy**
- **Warunki wstƒôpne**:
  - U≈ºytkownik zalogowany
  - Generation ID=123 istnieje
- **Kroki**:
  1. Wy≈õlij POST /api/flashcards/batch z 10 fiszkami
  2. Sprawd≈∫ response
  3. Sprawd≈∫ bazƒô danych
- **Oczekiwany rezultat**:
  - Status 200
  - created_count=10 w response
  - 10 nowych fiszek w tabeli flashcards z generation_id=123
  - Poprawne warto≈õci source (ai-full lub ai-edited)

**TS-INT-009: GET /api/reviews - fiszki do powt√≥rki**
- **Warunki wstƒôpne**:
  - U≈ºytkownik zalogowany
  - 20 fiszek w bazie
  - 10 fiszek ma next_review_date <= dzi≈õ
  - 10 fiszek ma next_review_date > dzi≈õ
- **Kroki**:
  1. Wy≈õlij GET /api/reviews
  2. Sprawd≈∫ response
- **Oczekiwany rezultat**:
  - Status 200
  - Zwr√≥cone 10 fiszek (tylko te do powt√≥rki)
  - Kolejno≈õƒá losowa (sprawdziƒá 2 wywo≈Çania)

**TS-INT-010: Middleware - ochrona nieautoryzowanych request√≥w**
- **Warunki wstƒôpne**: U≈ºytkownik niezalogowany
- **Kroki**:
  1. Wy≈õlij GET /api/flashcards bez session cookie
  2. Wy≈õlij POST /api/generations bez session cookie
- **Oczekiwany rezultat**:
  - Status 401 dla obu request√≥w
  - Komunikat: "Unauthorized"

**TS-INT-011: RLS - izolacja danych u≈ºytkownik√≥w**
- **Warunki wstƒôpne**:
  - User A zalogowany, posiada 10 fiszek
  - User B zalogowany, posiada 15 fiszek
- **Kroki**:
  1. Jako User A: GET /api/flashcards
  2. Jako User B: GET /api/flashcards
  3. Jako User A: pr√≥ba GET /api/flashcards/[id_fiszki_userB]
- **Oczekiwany rezultat**:
  - Request 1: 10 fiszek User A
  - Request 2: 15 fiszek User B
  - Request 3: Status 404 lub 403

### 3.3 Testy End-to-End (E2E Tests)

#### 3.3.1 Zakres
Testy pe≈Çnych scenariuszy u≈ºytkownika od UI do bazy danych.

#### 3.3.2 Narzƒôdzia
- **Playwright** lub **Cypress** - automatyzacja przeglƒÖdarki
- **Real database** - testy na ≈õrodowisku zbli≈ºonym do produkcji

#### 3.3.3 Priorytety
- **Priorytet 1 (Krytyczny)**:
  - Critical User Journey: Rejestracja ‚Üí Logowanie ‚Üí Generacja fiszek ‚Üí Zapis fiszek ‚Üí Powt√≥rka
  - Happy path dla wszystkich g≈Ç√≥wnych funkcji

- **Priorytet 2 (Wysoki)**:
  - Error handling w UI
  - Navigation i routing
  - Responsywno≈õƒá na urzƒÖdzeniach mobilnych

#### 3.3.4 Przyk≈Çadowe scenariusze testowe

**TS-E2E-001: Pe≈Çny flow u≈ºytkownika (Critical Path)**
- **Kroki**:
  1. Otw√≥rz /register
  2. Zarejestruj nowego u≈ºytkownika
  3. Zosta≈Ñ przekierowany do /login
  4. Zaloguj siƒô
  5. Zosta≈Ñ przekierowany do / (dashboard)
  6. Wklej tekst 2000 znak√≥w
  7. Kliknij "Generate Flashcards"
  8. Poczekaj na generacjƒô (sprawd≈∫ progress bar)
  9. Zobacz listƒô sugerowanych fiszek
  10. Edytuj 2 fiszki
  11. Zaznacz 8 fiszek do zapisu
  12. Kliknij "Save Selected"
  13. Zobacz potwierdzenie sukcesu
  14. Przejd≈∫ do listy fiszek
  15. Zweryfikuj 8 zapisanych fiszek (2 ai-edited, 6 ai-full)
- **Oczekiwany rezultat**: Wszystkie kroki wykonane bez b≈Çƒôd√≥w

**TS-E2E-002: Generacja fiszek - obs≈Çuga b≈Çƒôdu API**
- **Warunki wstƒôpne**: U≈ºytkownik zalogowany
- **Kroki**:
  1. Symuluj b≈ÇƒÖd OpenRouter API (mock lub wy≈ÇƒÖcz API key)
  2. Wklej tekst i kliknij Generate
  3. Obserwuj UI
- **Oczekiwany rezultat**:
  - Toast notification z b≈Çƒôdem
  - Przycisk "Retry" widoczny
  - Po klikniƒôciu Retry - ponowna pr√≥ba generacji

**TS-E2E-003: Wyszukiwanie fiszek**
- **Warunki wstƒôpne**:
  - U≈ºytkownik zalogowany
  - 50 fiszek w bazie danych
- **Kroki**:
  1. Przejd≈∫ do listy fiszek
  2. Wpisz "JavaScript" w pole wyszukiwania
  3. Naci≈õnij Enter
  4. Obserwuj wyniki
- **Oczekiwany rezultat**:
  - Lista filtruje siƒô do fiszek zawierajƒÖcych "JavaScript"
  - Pagination aktualizuje siƒô poprawnie
  - URL zawiera query parameter ?search=JavaScript

**TS-E2E-004: Responsywno≈õƒá na urzƒÖdzeniach mobilnych**
- **Kroki**:
  1. Otw√≥rz aplikacjƒô na viewport 375x667 (iPhone)
  2. Przejd≈∫ przez g≈Ç√≥wne ekrany:
     - Login
     - Dashboard
     - Generation view
     - Flashcard list
  3. Sprawd≈∫ czytelno≈õƒá i dostƒôpno≈õƒá element√≥w
- **Oczekiwany rezultat**:
  - Wszystkie elementy czytelne
  - Brak poziomego scrollowania
  - Przyciski dostƒôpne (nie zas≈Çoniƒôte)
  - Navigation dzia≈Ça poprawnie

**TS-E2E-005: Navigation blocking podczas reviewing**
- **Warunki wstƒôpne**: U≈ºytkownik w stanie "reviewing" (po generacji)
- **Kroki**:
  1. Pr√≥buj opu≈õciƒá stronƒô (kliknij Back, Close tab)
  2. Obserwuj dialog
  3. Anuluj dialog
  4. Zapisz fiszki
  5. Pr√≥buj opu≈õciƒá stronƒô ponownie
- **Oczekiwany rezultat**:
  - Krok 2: Dialog potwierdzenia "You have unsaved changes"
  - Krok 3: Pozostajesz na stronie
  - Krok 5: Brak dialogu, swobodna nawigacja

### 3.4 Testy Wydajno≈õciowe (Performance Tests)

#### 3.4.1 Zakres
Weryfikacja czas√≥w odpowiedzi i zachowania pod obciƒÖ≈ºeniem.

#### 3.4.2 Narzƒôdzia
- **Apache JMeter** lub **k6** - load testing
- **Lighthouse** - wydajno≈õƒá frontendu
- **Chrome DevTools Performance tab** - analiza renderowania

#### 3.4.3 Metryki docelowe
- **Time to First Byte (TTFB)**: < 200ms (dla API endpoints)
- **First Contentful Paint (FCP)**: < 1.8s
- **Largest Contentful Paint (LCP)**: < 2.5s
- **Time to Interactive (TTI)**: < 3.5s
- **Cumulative Layout Shift (CLS)**: < 0.1
- **API Response Time**:
  - GET endpoints: < 100ms (95th percentile)
  - POST endpoints (bez AI): < 200ms (95th percentile)
  - POST /api/generations (z AI): < 10s (95th percentile)

#### 3.4.4 Przyk≈Çadowe scenariusze testowe

**TS-PERF-001: Load test - GET /api/flashcards**
- **Konfiguracja**:
  - 100 concurrent users
  - Duration: 5 minut
  - Think time: 2-5 sekund
- **Kroki**:
  1. Ka≈ºdy user loguje siƒô
  2. Wykonuje GET /api/flashcards z losowƒÖ paginacjƒÖ
  3. Powtarza kroki 2-3
- **Oczekiwany rezultat**:
  - 95th percentile response time < 100ms
  - Error rate < 1%
  - Database connection pool nie wyczerpany

**TS-PERF-002: Stress test - POST /api/generations**
- **Konfiguracja**:
  - 50 concurrent users
  - Duration: 3 minuty
  - Ramp-up: 30 sekund
- **Kroki**:
  1. Ka≈ºdy user wykonuje POST /api/generations
  2. Monitoruj rate limiting (5 req/min per user)
- **Oczekiwany rezultat**:
  - 95th percentile response time < 10s
  - Rate limiting dzia≈Ça (6. request zwraca 429)
  - OpenRouter API nie przeciƒÖ≈ºone
  - Brak memory leaks

**TS-PERF-003: Frontend Performance - Generation View**
- **Narzƒôdzie**: Lighthouse
- **Kroki**:
  1. Za≈Çaduj /generate
  2. Uruchom Lighthouse audit
- **Oczekiwany rezultat**:
  - Performance score > 90
  - FCP < 1.8s
  - LCP < 2.5s
  - TTI < 3.5s
  - CLS < 0.1

**TS-PERF-004: Database query optimization - Full-text search**
- **Warunki wstƒôpne**: 10,000 fiszek w bazie
- **Kroki**:
  1. Wykonaj GET /api/flashcards?search=common_word
  2. Zmierz czas odpowiedzi
  3. Sprawd≈∫ query plan w PostgreSQL (EXPLAIN ANALYZE)
- **Oczekiwany rezultat**:
  - Response time < 150ms
  - GIN index na fts_vector wykorzystany
  - Brak sequential scan

**TS-PERF-005: Memory leak test - d≈Çugotrwa≈Ça sesja**
- **Konfiguracja**: Single user, 60 minut sesji
- **Kroki**:
  1. User wykonuje mix operacji (generacja, CRUD fiszek)
  2. Monitoruj memory usage w przeglƒÖdarce (Chrome DevTools)
- **Oczekiwany rezultat**:
  - Brak nieograniczonego wzrostu memory
  - Memory usage stabilizuje siƒô < 150MB

### 3.5 Testy Bezpiecze≈Ñstwa (Security Tests)

#### 3.5.1 Zakres
Weryfikacja mechanizm√≥w bezpiecze≈Ñstwa i ochrony przed typowymi atakami.

#### 3.5.2 Narzƒôdzia
- **OWASP ZAP** - automatyczne skanowanie podatno≈õci
- **Manual penetration testing** - testy manualne
- **Burp Suite Community** - analiza request√≥w

#### 3.5.3 Przyk≈Çadowe scenariusze testowe

**TS-SEC-001: SQL Injection w wyszukiwaniu**
- **Kroki**:
  1. Wy≈õlij GET /api/flashcards?search=' OR '1'='1
  2. Wy≈õlij GET /api/flashcards?search='; DROP TABLE flashcards; --
- **Oczekiwany rezultat**:
  - Brak wykonania SQL injection
  - Parametry prawid≈Çowo escapowane przez Supabase client
  - Status 200 lub 400 (walidacja)

**TS-SEC-002: XSS w tre≈õci fiszek**
- **Kroki**:
  1. Stw√≥rz fiszkƒô z front: `<script>alert('XSS')</script>`
  2. Wy≈õwietl fiszkƒô w UI
  3. Sprawd≈∫ DevTools Console
- **Oczekiwany rezultat**:
  - Script nie wykonany
  - React automatycznie escapuje HTML
  - Tre≈õƒá wy≈õwietlona jako plain text

**TS-SEC-003: CSRF - unauthorized actions**
- **Kroki**:
  1. User A zalogowany
  2. Z innej domeny wy≈õlij POST /api/flashcards z credentials User A
- **Oczekiwany rezultat**:
  - Request odrzucony (CORS policy lub CSRF token)
  - Status 403 lub 401

**TS-SEC-004: Authorization bypass - dostƒôp do cudzych fiszek**
- **Warunki wstƒôpne**:
  - User A zalogowany
  - User B posiada fiszkƒô ID=999
- **Kroki**:
  1. Jako User A: wy≈õlij GET /api/flashcards/999
  2. Jako User A: wy≈õlij PUT /api/flashcards/999
  3. Jako User A: wy≈õlij DELETE /api/flashcards/999
- **Oczekiwany rezultat**:
  - Wszystkie requesty zwracajƒÖ 403 lub 404
  - Dane User B niezmienione

**TS-SEC-005: Rate limiting bypass**
- **Kroki**:
  1. Wy≈õlij 6 request√≥w POST /api/generations w ciƒÖgu minuty
  2. Zmie≈Ñ User-Agent i wy≈õlij kolejne 6 request√≥w
  3. Zmie≈Ñ IP (proxy) i wy≈õlij kolejne 6 request√≥w
- **Oczekiwany rezultat**:
  - Request 6 w kroku 1: Status 429
  - Kroki 2-3: Rate limiting nadal dzia≈Ça (bazuje na user_id, nie IP/UA)

**TS-SEC-006: Sensitive data exposure w API responses**
- **Kroki**:
  1. Wy≈õlij GET /api/flashcards
  2. Sprawd≈∫ response JSON
  3. Wy≈õlij GET /api/reviews
  4. Sprawd≈∫ response JSON
- **Oczekiwany rezultat**:
  - Brak p√≥l: user_id, password hash, fts_vector, internal IDs
  - Tylko publiczne DTO fields (zgodnie z typami w src/types.ts)

**TS-SEC-007: Password strength validation**
- **Kroki**:
  1. Pr√≥buj zarejestrowaƒá siƒô z has≈Çem "123"
  2. Pr√≥buj zarejestrowaƒá siƒô z has≈Çem "password"
  3. Pr√≥buj zarejestrowaƒá siƒô z has≈Çem "P@ssw0rd!"
- **Oczekiwany rezultat**:
  - Krok 1: B≈ÇƒÖd (za kr√≥tkie, min 6 znak√≥w)
  - Krok 2: Sukces (je≈õli >= 6 znak√≥w) lub zalecenie silniejszego has≈Ça
  - Krok 3: Sukces

**TS-SEC-008: Session fixation i hijacking**
- **Kroki**:
  1. User A loguje siƒô, otrzymuje session cookie
  2. User B pr√≥buje u≈ºyƒá session cookie User A
  3. User A wylogowuje siƒô
  4. User B pr√≥buje u≈ºyƒá starego cookie User A
- **Oczekiwany rezultat**:
  - Krok 2: Zale≈ºne od implementacji Supabase (prawdopodobnie odrzucone)
  - Krok 4: Session niewa≈ºna, Status 401

### 3.6 Testy Dostƒôpno≈õci (Accessibility Tests)

#### 3.6.1 Zakres
Weryfikacja zgodno≈õci z WCAG 2.1 Level AA.

#### 3.6.2 Narzƒôdzia
- **axe DevTools** - automatyczne wykrywanie problem√≥w a11y
- **NVDA/JAWS** - screen reader testing
- **Lighthouse Accessibility audit**
- **Manual keyboard navigation testing**

#### 3.6.3 Przyk≈Çadowe scenariusze testowe

**TS-A11Y-001: Keyboard navigation - pe≈Çna funkcjonalno≈õƒá**
- **Kroki**:
  1. Bez myszy, nawiguj przez ca≈ÇƒÖ aplikacjƒô u≈ºywajƒÖc Tab/Shift+Tab
  2. U≈ºyj Enter/Space do aktywacji przycisk√≥w
  3. U≈ºyj Escape do zamykania dialog√≥w
  4. U≈ºyj strza≈Çek w listach fiszek
- **Oczekiwany rezultat**:
  - Wszystkie interaktywne elementy osiƒÖgalne
  - Focus indicator widoczny
  - Focus trap w modalach/dialogach
  - Logiczna kolejno≈õƒá tabulacji

**TS-A11Y-002: Screen reader - formularz logowania**
- **Narzƒôdzie**: NVDA (Windows) lub VoiceOver (macOS)
- **Kroki**:
  1. Otw√≥rz /login
  2. U≈ºyj screen readera do nawigacji
  3. Wype≈Çnij formularz
  4. Wy≈õlij formularz
  5. Pos≈Çuchaj komunikat√≥w b≈Çƒôd√≥w (je≈õli sƒÖ)
- **Oczekiwany rezultat**:
  - Label'e p√≥l formularza odczytane poprawnie
  - Komunikaty b≈Çƒôd√≥w po≈ÇƒÖczone z polami (aria-describedby)
  - Status submission odczytany (toast lub live region)

**TS-A11Y-003: Color contrast - wszystkie teksty**
- **Narzƒôdzie**: Lighthouse + manual inspection
- **Kroki**:
  1. Sprawd≈∫ contrast ratio dla wszystkich tekst√≥w (body, headings, buttons)
  2. Sprawd≈∫ contrast w dark mode (je≈õli istnieje)
- **Oczekiwany rezultat**:
  - Normal text: ‚â• 4.5:1
  - Large text (‚â•18pt): ‚â• 3:1
  - UI components: ‚â• 3:1

**TS-A11Y-004: ARIA attributes - correctness**
- **Narzƒôdzie**: axe DevTools
- **Kroki**:
  1. Skanuj wszystkie strony aplikacji
  2. Sprawd≈∫ raporty b≈Çƒôd√≥w
- **Oczekiwany rezultat**:
  - Brak critical/serious issues w axe
  - ARIA roles poprawnie u≈ºyte
  - aria-label/aria-labelledby obecne gdzie potrzebne
  - aria-live regions dla dynamicznych aktualizacji

**TS-A11Y-005: Focus management - modal dialog**
- **Kroki**:
  1. Otw√≥rz modal FlashcardModal
  2. Sprawd≈∫, czy focus przeskoczy≈Ç do modala
  3. Pr√≥buj Tab poza modal
  4. Zamknij modal (Escape lub przycisk)
  5. Sprawd≈∫, gdzie wr√≥ci≈Ç focus
- **Oczekiwany rezultat**:
  - Focus automatycznie w modalu przy otwarciu
  - Focus trap - Tab nie wychodzi poza modal
  - Po zamkniƒôciu focus wraca do triggera (przycisku, kt√≥ry otworzy≈Ç modal)

### 3.7 Testy Kompatybilno≈õci (Compatibility Tests)

#### 3.7.1 Zakres
Weryfikacja dzia≈Çania w r√≥≈ºnych przeglƒÖdarkach, OS i urzƒÖdzeniach.

#### 3.7.2 Testowane ≈õrodowiska
- **Desktop**:
  - Chrome (latest, latest-1)
  - Firefox (latest, latest-1)
  - Safari (latest, macOS)
  - Edge (latest, Windows)
- **Mobile**:
  - Chrome Mobile (Android)
  - Safari Mobile (iOS latest, latest-1)
  - Samsung Internet (Android)
- **Rozdzielczo≈õci**:
  - Desktop: 1920x1080, 1366x768
  - Tablet: 768x1024
  - Mobile: 375x667, 414x896

#### 3.7.3 Przyk≈Çadowe scenariusze testowe

**TS-COMP-001: Cross-browser - critical path**
- **Kroki**:
  1. Powt√≥rz TS-E2E-001 (Critical Path) na ka≈ºdej przeglƒÖdarce z listy
- **Oczekiwany rezultat**:
  - Identyczna funkcjonalno≈õƒá we wszystkich przeglƒÖdarkach
  - Brak b≈Çƒôd√≥w JavaScript w console

**TS-COMP-002: Responsive - mobile viewport**
- **UrzƒÖdzenie**: iPhone 12 (390x844), Android Galaxy S21 (360x800)
- **Kroki**:
  1. Otw√≥rz aplikacjƒô
  2. Sprawd≈∫ layout g≈Ç√≥wnych ekran√≥w
  3. Przetestuj dotyk vs klawiatura mobilna
- **Oczekiwany rezultat**:
  - Layout nie zepsuje siƒô
  - Przyciski du≈ºe enough (min 44x44px tap target)
  - Brak poziomego scrollowania

**TS-COMP-003: Safari-specific issues**
- **PrzeglƒÖdarka**: Safari 17+ (macOS, iOS)
- **Kroki**:
  1. Test fetch API w endpointach
  2. Test date formatting
  3. Test CSS Grid/Flexbox layouts
  4. Test Tailwind classes
- **Oczekiwany rezultat**:
  - Wszystkie features dzia≈ÇajƒÖ (Safari czasem ma op√≥≈∫nienia w adopcji nowych API)

## 4. Scenariusze Testowe dla Kluczowych Funkcjonalno≈õci

*(Szczeg√≥≈Çowe scenariusze zosta≈Çy ju≈º opisane w sekcji 3 - Typy Test√≥w)*

**Podsumowanie priorytet√≥w kluczowych funkcjonalno≈õci**:

### 4.1 Funkcjonalno≈õci Krytyczne (Priorytet 1)
1. Rejestracja i logowanie u≈ºytkownik√≥w
2. Generacja fiszek z AI (POST /api/generations)
3. Zapis wsadowy fiszek (POST /api/flashcards/batch)
4. Pobieranie listy fiszek z paginacjƒÖ (GET /api/flashcards)
5. System powt√≥rek (GET /api/reviews)
6. Rate limiting middleware
7. Row-Level Security (RLS) w Supabase

### 4.2 Funkcjonalno≈õci Wysokiego Priorytetu (Priorytet 2)
1. CRUD pojedynczych fiszek (POST/PUT/DELETE /api/flashcards/:id)
2. Pe≈Çnotekstowe wyszukiwanie (GET /api/flashcards?search=...)
3. Obs≈Çuga b≈Çƒôd√≥w generacji (retry z exponential backoff)
4. Navigation blocking podczas reviewing
5. Character counter w UI
6. Toast notifications

### 4.3 Funkcjonalno≈õci ≈öredniego Priorytetu (Priorytet 3)
1. Odzyskiwanie has≈Ça
2. InfoBox expand/collapse
3. Progress bar podczas generacji
4. Confirm dialog przy opuszczaniu strony
5. Mock mode dla development

## 5. ≈örodowisko Testowe

### 5.1 ≈örodowiska

#### 5.1.1 Lokalne (Development)
- **Cel**: Testy jednostkowe i integracyjne podczas development
- **Konfiguracja**:
  - Node.js 20+
  - npm/pnpm
  - Supabase CLI z lokalnƒÖ instancjƒÖ (supabase start)
  - Mock OpenRouter API (tryb mock)
- **Dane**: Seeded database z przyk≈Çadowymi danymi

#### 5.1.2 Staging/Test
- **Cel**: Testy E2E, wydajno≈õciowe, bezpiecze≈Ñstwa
- **Konfiguracja**:
  - ≈örodowisko zbli≈ºone do produkcji
  - Supabase hosted instance (dedykowana dla test√≥w)
  - OpenRouter API z limitowanym kluczem (lub mock)
- **Dane**: Realistyczne dane testowe, odizolowane od produkcji

#### 5.1.3 Produkcja (Limited Testing)
- **Cel**: Smoke tests po deployment
- **Konfiguracja**: ≈örodowisko produkcyjne
- **Dane**: Prawdziwe dane (tylko odczyt, bez modyfikacji)
- **Scope**: Tylko krytyczne smoke tests (health checks, basic login)

### 5.2 Dane Testowe

#### 5.2.1 U≈ºytkownicy testowi
- **test-user-1@example.com** / "P@ssw0rd1" - u≈ºytkownik z 100 fiszkami
- **test-user-2@example.com** / "P@ssw0rd2" - u≈ºytkownik z 0 fiszkami (nowy)
- **test-admin@example.com** / "AdminP@ss" - admin (je≈õli role w przysz≈Ço≈õci)

#### 5.2.2 Fiszki testowe
- 100 fiszek o r√≥≈ºnej tematyce (historia, biologia, programowanie)
- R√≥≈ºne d≈Çugo≈õci tekstu (kr√≥tkie, ≈õrednie, d≈Çugie)
- R√≥≈ºne ≈∫r√≥d≈Ça (manual, ai-full, ai-edited)
- R√≥≈ºne daty created_at (do testowania sortowania)

#### 5.2.3 Dane spaced repetition
- Fiszki z r√≥≈ºnymi next_review_date:
  - 30 fiszek: wczoraj (overdue)
  - 20 fiszek: dzi≈õ
  - 50 fiszek: przysz≈Ço≈õƒá

### 5.3 Konfiguracja testowa

#### 5.3.1 Zmienne ≈õrodowiskowe (.env.test)
```bash
PUBLIC_SUPABASE_URL=http://localhost:54321
PUBLIC_SUPABASE_ANON_KEY=eyJhbGc...
OPENROUTER_API_KEY=sk-test-mock-key
MOCK_MODE=true
NODE_ENV=test
```

#### 5.3.2 Database migrations
- Automatyczne uruchamianie migracji przed testami
- Rollback po ka≈ºdym te≈õcie dla izolacji
- Seeding danych testowych via skrypty SQL

## 6. Narzƒôdzia do Testowania

### 6.1 Testy Jednostkowe
- **Framework**: Vitest (fast, ESM-native, kompatybilny z Vite/Astro)
- **Mocking**: vitest/vi + @vitest/spy
- **Coverage**: c8 / v8 (wbudowane w Vitest)
- **React testing**: @testing-library/react + @testing-library/jest-dom

### 6.2 Testy Integracyjne
- **API Testing**: Supertest + Node Test Runner
- **Database**: PostgreSQL (local Supabase instance)
- **Mocking**: MSW (Mock Service Worker) dla OpenRouter API

### 6.3 Testy E2E
- **Framework**: Playwright (szybki, multi-browser, great debugging)
- **Alternative**: Cypress (je≈õli zesp√≥≈Ç preferuje)
- **Visual Regression**: Percy lub Playwright screenshots

### 6.4 Testy Wydajno≈õciowe
- **Load Testing**: k6 (scripting w JavaScript, cloud results)
- **Frontend Performance**: Lighthouse CI (automated)
- **Monitoring**: Chrome DevTools Performance/Memory profiler

### 6.5 Testy Bezpiecze≈Ñstwa
- **SAST**: ESLint security plugins, semgrep
- **DAST**: OWASP ZAP (automated scan)
- **Dependency Scanning**: npm audit, Snyk

### 6.6 Testy Dostƒôpno≈õci
- **Automated**: axe-core + @axe-core/playwright
- **Manual**: NVDA (Windows), VoiceOver (macOS)
- **Audit**: Lighthouse Accessibility score

### 6.7 CI/CD Integration
- **Pipeline**: GitHub Actions
- **Stages**:
  1. Lint (ESLint, Prettier check)
  2. Unit tests (Vitest)
  3. Integration tests (Supertest)
  4. E2E tests (Playwright)
  5. Build (Astro build)
  6. Security scan (npm audit)
- **Reports**: Test results w GitHub Actions summary
- **Coverage**: Upload do Codecov lub Coveralls

## 7. Harmonogram Test√≥w

### 7.1 Faza 1: Przygotowanie (Tydzie≈Ñ 1)
- **Dzie≈Ñ 1-2**: Setup ≈õrodowiska testowego (lokalne, staging)
- **Dzie≈Ñ 3-4**: Instalacja narzƒôdzi testowych (Vitest, Playwright, k6)
- **Dzie≈Ñ 5**: Przygotowanie danych testowych (seeding scripts)
- **Dzie≈Ñ 6-7**: Napisanie test utils i helper functions

### 7.2 Faza 2: Testy Jednostkowe (Tydzie≈Ñ 2-3)
- **Tydzie≈Ñ 2**: Testy serwis√≥w (`src/lib/services/`)
  - Priorytet: flashcard.service, generation.service, review.service
- **Tydzie≈Ñ 3**: Testy hook√≥w i utility functions
  - Priorytet: useGenerationViewState, crypto.ts, utils.ts

### 7.3 Faza 3: Testy Integracyjne (Tydzie≈Ñ 3-4)
- **Tydzie≈Ñ 3 (kontynuacja)**: Endpointy autentykacji
  - POST /api/auth/register, /api/auth/login, /api/auth/logout
- **Tydzie≈Ñ 4**: Endpointy flashcards i generations
  - GET/POST /api/flashcards, POST /api/flashcards/batch
  - POST /api/generations
- **Tydzie≈Ñ 4 (koniec)**: Middleware i RLS

### 7.4 Faza 4: Testy E2E (Tydzie≈Ñ 5)
- **Dzie≈Ñ 1-2**: Critical path (TS-E2E-001)
- **Dzie≈Ñ 3-4**: Error handling scenarios
- **Dzie≈Ñ 5**: Responsywno≈õƒá i navigation

### 7.5 Faza 5: Testy Niefunkcjonalne (Tydzie≈Ñ 6)
- **Dzie≈Ñ 1-2**: Performance testing (load, stress tests)
- **Dzie≈Ñ 3**: Security testing (OWASP ZAP, manual pentesting)
- **Dzie≈Ñ 4**: Accessibility testing (axe, screen readers)
- **Dzie≈Ñ 5**: Compatibility testing (cross-browser)

### 7.6 Faza 6: Regression i Bug Fixing (Tydzie≈Ñ 7)
- **Dzie≈Ñ 1-3**: Fixing found issues
- **Dzie≈Ñ 4-5**: Regression testing (re-run failed tests)
- **Dzie≈Ñ 6-7**: Final smoke tests, dokumentacja wynik√≥w

### 7.7 Ongoing: Maintenance
- **Post-release**: Automated tests w CI/CD przy ka≈ºdym PR/commit
- **Weekly**: PrzeglƒÖd code coverage i test failures
- **Monthly**: Audit bezpiecze≈Ñstwa i dependency updates

## 8. Kryteria Akceptacji Test√≥w

### 8.1 Kryteria funkcjonalne

#### 8.1.1 Testy jednostkowe
- ‚úÖ **Minimum 80% code coverage** (functions, branches)
- ‚úÖ **100% coverage dla serwis√≥w krytycznych** (generation.service, flashcard.service)
- ‚úÖ **Wszystkie testy przechodzƒÖ** (0 failures, 0 skipped)
- ‚úÖ **Test execution time < 2 minuty** (dla szybkiego feedback loop)

#### 8.1.2 Testy integracyjne
- ‚úÖ **90% coverage dla API endpoints** (wszystkie krytyczne endpointy pokryte)
- ‚úÖ **Wszystkie scenariusze happy path i error handling** przetestowane
- ‚úÖ **RLS policies zweryfikowane** (izolacja danych u≈ºytkownik√≥w)
- ‚úÖ **Rate limiting dzia≈Ça** poprawnie

#### 8.1.3 Testy E2E
- ‚úÖ **Critical user journey (TS-E2E-001) przechodzi** w 100%
- ‚úÖ **Wszystkie main features** funkcjonalne w UI
- ‚úÖ **Error handling w UI** dzia≈Ça (toasts, dialogs)
- ‚úÖ **Responsywno≈õƒá** na mobile i desktop potwierdzona

### 8.2 Kryteria niefunkcjonalne

#### 8.2.1 Wydajno≈õƒá
- ‚úÖ **API response times** w granicach SLA (sekcja 3.4.3)
- ‚úÖ **Frontend performance**: Lighthouse score > 90
- ‚úÖ **Load test**: system obs≈Çuguje 100 concurrent users bez degradacji
- ‚úÖ **Memory**: Brak memory leaks podczas d≈Çugotrwa≈Çych sesji

#### 8.2.2 Bezpiecze≈Ñstwo
- ‚úÖ **Zero critical/high vulnerabilities** w OWASP ZAP scan
- ‚úÖ **Autoryzacja i autentykacja** dzia≈ÇajƒÖ poprawnie (wszystkie scenariusze TS-SEC)
- ‚úÖ **Sensitive data** nie jest eksponowane w API responses
- ‚úÖ **HTTPS enforced** (w produkcji)
- ‚úÖ **npm audit**: zero vulnerabilities (lub wszystkie zmitigowane)

#### 8.2.3 Dostƒôpno≈õƒá
- ‚úÖ **axe-core**: zero critical/serious issues
- ‚úÖ **Lighthouse Accessibility**: score > 90
- ‚úÖ **Keyboard navigation**: pe≈Çna funkcjonalno≈õƒá (TS-A11Y-001)
- ‚úÖ **Screen reader**: main features dostƒôpne (TS-A11Y-002)
- ‚úÖ **Color contrast**: spe≈Çnia WCAG 2.1 AA

#### 8.2.4 Kompatybilno≈õƒá
- ‚úÖ **Critical path dzia≈Ça** we wszystkich przeglƒÖdarkach z listy (sekcja 3.7.2)
- ‚úÖ **Responsive design**: dzia≈Ça na wszystkich rozdzielczo≈õciach (desktop, tablet, mobile)
- ‚úÖ **No JavaScript errors** w console na ≈ºadnej przeglƒÖdarce

### 8.3 Kryteria dotyczƒÖce b≈Çƒôd√≥w

#### 8.3.1 Severity classification
- **Blocker**: System ca≈Çkowicie nieu≈ºywalny (np. nie mo≈ºna siƒô zalogowaƒá)
- **Critical**: G≈Ç√≥wna funkcjonalno≈õƒá nie dzia≈Ça (np. generacja fiszek failuje zawsze)
- **Major**: Wa≈ºna funkcjonalno≈õƒá ma problemy (np. wyszukiwanie nie dzia≈Ça)
- **Minor**: Drobne problemy UX (np. toast nie znika automatycznie)
- **Trivial**: Kosmetyczne (np. typo w tek≈õcie)

#### 8.3.2 Acceptable bug counts (exit criteria)
- ‚úÖ **Blocker**: 0
- ‚úÖ **Critical**: 0
- ‚úÖ **Major**: ‚â§ 3 (z planem fix w kolejnym sprincie)
- ‚úÖ **Minor**: ‚â§ 10 (mogƒÖ byƒá odroczone)
- ‚úÖ **Trivial**: bez limitu (mogƒÖ byƒá w backlogu)

### 8.4 Dokumentacja
- ‚úÖ **Wszystkie failed tests** majƒÖ zg≈Çoszenia bug (w GitHub Issues)
- ‚úÖ **Test execution report** przygotowany (summary, statistics)
- ‚úÖ **Known issues** udokumentowane (workarounds je≈õli istniejƒÖ)
- ‚úÖ **Test coverage report** wygenerowany i zarchiwizowany

## 9. Role i Odpowiedzialno≈õci w Procesie Testowania

### 9.1 QA Engineer / Test Engineer (G≈Ç√≥wny tester)
**Odpowiedzialno≈õci**:
- Tworzenie i utrzymanie test cases i test scenarios
- Wykonywanie test√≥w manualnych (E2E, exploratory)
- Konfiguracja i maintenance ≈õrodowisk testowych
- Raportowanie bug√≥w i tracking ich statusu
- PrzeglƒÖd i aktualizacja planu test√≥w
- Koordynacja test√≥w akceptacyjnych z Product Ownerem

**Deliverables**:
- Test case documentation
- Test execution reports
- Bug reports (GitHub Issues)
- Test data scripts

### 9.2 Developer / Software Engineer
**Odpowiedzialno≈õci**:
- Pisanie test√≥w jednostkowych dla w≈Çasnego kodu
- Pisanie test√≥w integracyjnych dla API endpoints
- Fixing bug√≥w znalezionych przez QA
- Code review z perspektywy testability
- Maintenance test automation scripts (Vitest, Playwright)
- Zapewnienie > 80% code coverage

**Deliverables**:
- Unit tests (Vitest)
- Integration tests (Supertest)
- Bug fixes
- Code coverage reports

### 9.3 DevOps Engineer
**Odpowiedzialno≈õci**:
- Setup i maintenance CI/CD pipeline z testami
- Konfiguracja staging environment
- Automated deployment po przej≈õciu test√≥w
- Monitoring performance metrics w produkcji
- Setup narzƒôdzi testowych (k6, OWASP ZAP w pipeline)

**Deliverables**:
- CI/CD pipeline configuration (GitHub Actions)
- Environment setup scripts
- Performance monitoring dashboards

### 9.4 Product Owner / Project Manager
**Odpowiedzialno≈õci**:
- Zatwierdzanie planu test√≥w i kryteri√≥w akceptacji
- Priorytetyzacja bug√≥w do fix
- Podejmowanie decyzji go/no-go dla release
- Akceptacja user acceptance tests (UAT)
- ZarzƒÖdzanie ryzykiem i scope

**Deliverables**:
- Approved test plan
- Bug prioritization decisions
- UAT sign-off
- Release decision documentation

### 9.5 Security Specialist (opcjonalnie, mo≈ºe byƒá external)
**Odpowiedzialno≈õci**:
- Przeprowadzenie penetration testing
- PrzeglƒÖd security test results (OWASP ZAP)
- Audyt bezpiecze≈Ñstwa kodu (SAST)
- Rekomendacje zabezpiecze≈Ñ

**Deliverables**:
- Penetration testing report
- Security recommendations
- Threat model analysis

### 9.6 UX/UI Designer
**Odpowiedzialno≈õci**:
- Weryfikacja accessibility w UI
- PrzeglƒÖd responsywno≈õci na r√≥≈ºnych urzƒÖdzeniach
- Validacja zgodno≈õci implementacji z designem
- Testy u≈ºyteczno≈õci (usability testing)

**Deliverables**:
- Accessibility audit results
- Usability test findings
- Design-implementation gap analysis

## 10. Procedury Raportowania B≈Çƒôd√≥w

### 10.1 Narzƒôdzie do zarzƒÖdzania b≈Çƒôdami
**GitHub Issues** (zintegrowane z repo projektu)

### 10.2 Szablon zg≈Çoszenia b≈Çƒôdu (Bug Report Template)

```markdown
## üêõ Bug Report

### Tytu≈Ç
[Kr√≥tki, opisowy tytu≈Ç b≈Çƒôdu]

### Severity
- [ ] Blocker
- [ ] Critical
- [ ] Major
- [ ] Minor
- [ ] Trivial

### ≈örodowisko
- **OS**: [np. macOS 13.4, Windows 11]
- **PrzeglƒÖdarka**: [np. Chrome 120, Safari 17]
- **URL**: [np. https://app.example.com/generate]
- **User**: [np. test-user-1@example.com]

### Opis problemu
[Jasny i zwiƒôz≈Çy opis tego, co jest nie tak]

### Kroki do reprodukcji
1. Otw√≥rz stronƒô X
2. Kliknij przycisk Y
3. Wprowad≈∫ warto≈õƒá Z
4. Obserwuj b≈ÇƒÖd

### Oczekiwane zachowanie
[Co powinno siƒô staƒá]

### Rzeczywiste zachowanie
[Co faktycznie siƒô dzieje]

### Screenshoty / Logi
[Za≈ÇƒÖcz screenshoty lub logi z konsoli]

```javascript
// Console errors (je≈õli sƒÖ)
TypeError: Cannot read property 'id' of undefined
  at GenerationView.tsx:142
```

### Dodatkowe informacje
- Test Case ID: [np. TS-E2E-003]
- First occurrence: [data/czas]
- Reproducibility: [Always / Sometimes / Rarely]
- Related Issues: [linki do powiƒÖzanych issues]

### Proponowane rozwiƒÖzanie (opcjonalne)
[Je≈õli masz pomys≈Ç na fix]
```

### 10.3 Workflow zg≈Çoszenia b≈Çƒôdu

#### 10.3.1 Nowe zg≈Çoszenie
1. **QA/Tester** tworzy issue w GitHub z u≈ºyciem template
2. Przypisuje label: `bug`, severity label (np. `severity:critical`)
3. Dodaje do odpowiedniego Milestone (je≈õli dotyczy konkretnego release)
4. Opcjonalnie: przypisuje do developera (je≈õli wiadomo, kto jest owner)

#### 10.3.2 Triage (Priorytetyzacja)
1. **Product Owner + Tech Lead** przeglƒÖdajƒÖ nowe bugi (codziennie lub 2x/tydzie≈Ñ)
2. WalidujƒÖ severity
3. PrzypisujƒÖ priorytet (P0, P1, P2, P3)
4. DecydujƒÖ o assignment (developer) i target sprint

#### 10.3.3 In Progress
1. **Developer** zmienia status na "In Progress" (Project board)
2. Pracuje nad fixem, dodaje unit test reprodukujƒÖcy bug
3. Tworzy Pull Request z referencjƒÖ do issue (#123)
4. PR review przez code review + QA preview

#### 10.3.4 Verification
1. **QA** testuje fix w ≈õrodowisku staging (po merge PR)
2. Je≈õli OK: zmienia status na "Verified", zamyka issue
3. Je≈õli NOK: reopens issue z komentarzem, wraca do In Progress

#### 10.3.5 Closed
1. Bug zweryfikowany i naprawiony
2. Issue zamkniƒôty (automatically przy merge PR lub manual)
3. W≈ÇƒÖczony do regression test suite (je≈õli applicable)

### 10.4 Poziomy priorytet√≥w

#### P0 (Blocker) - Fix immediately
- System ca≈Çkowicie nieu≈ºywalny
- Bezpiecze≈Ñstwo: critical vulnerability
- **SLA**: Fix w ciƒÖgu 24h, hotfix deployment

#### P1 (Critical) - Fix in current sprint
- G≈Ç√≥wna funkcjonalno≈õƒá broken
- Dotyczy du≈ºej liczby u≈ºytkownik√≥w
- **SLA**: Fix w ciƒÖgu 3-5 dni roboczych

#### P2 (Major) - Fix in next sprint
- Wa≈ºna funkcjonalno≈õƒá ma problemy
- Workaround istnieje
- **SLA**: Fix w ciƒÖgu 2 tygodni

#### P3 (Minor/Trivial) - Backlog
- Kosmetyczne lub edge case
- Niski wp≈Çyw na u≈ºytkownik√≥w
- **SLA**: Fix "when possible", mo≈ºe byƒá od≈Ço≈ºone

### 10.5 Metryki i raportowanie

#### 10.5.1 Tygodniowy raport dla zespo≈Çu
- Liczba nowych bug√≥w (breakdown by severity)
- Liczba zamkniƒôtych bug√≥w
- Liczba bug√≥w in progress
- Top 5 najstarszych otwartych bug√≥w (potential bottlenecks)
- Bug fix velocity (ile bug√≥w zamykamy per sprint)

#### 10.5.2 Miesiƒôczny raport dla managementu
- Trend bug√≥w w czasie (czy ro≈õnie/maleje)
- Bug severity distribution (pie chart)
- Areas with most bugs (np. generation module vs auth module)
- Time to resolve (≈õredni czas ≈ºycia buga)
- Quality metrics (% test√≥w przechodzƒÖcych, code coverage trend)

### 10.6 Eskalacja

**Krok 1**: Bug reported przez QA ‚Üí assigned to Developer
**Krok 2**: Je≈õli nie rozwiƒÖzany w SLA ‚Üí eskalacja do Tech Lead
**Krok 3**: Je≈õli blocker/critical i wymaga wiƒôcej zasob√≥w ‚Üí eskalacja do Product Owner / Project Manager
**Krok 4**: Je≈õli dotyczy bezpiecze≈Ñstwa (critical vulnerability) ‚Üí natychmiastowa eskalacja + powiadomienie Security Specialist

---

## 11. Za≈ÇƒÖczniki

### 11.1 Checklist pre-deployment (Go/No-Go)

**Pre-Production Deployment Checklist**:

- [ ] Wszystkie critical/blocker bugs zamkniƒôte
- [ ] Code coverage > 80% (unit tests)
- [ ] Wszystkie E2E tests przechodzƒÖ (critical path)
- [ ] Performance tests w granicach SLA
- [ ] Security scan (OWASP ZAP) - zero critical issues
- [ ] Accessibility audit (axe) - zero critical/serious issues
- [ ] Compatibility testing - wszystkie target browsers OK
- [ ] Database migrations przetestowane (staging)
- [ ] Rollback plan przygotowany
- [ ] Monitoring i alerting skonfigurowane
- [ ] Documentation zaktualizowana (README, API docs)
- [ ] Stakeholders poinformowani o deployment window

### 11.2 Slownik termin√≥w

- **SUT (System Under Test)**: Testowany system, aplikacja do generowania fiszek
- **Supabase**: Backend-as-a-Service (BaaS), zarzƒÖdza DB i auth
- **OpenRouter**: Us≈Çuga proxy do API AI models
- **RLS (Row-Level Security)**: Mechanizm bezpiecze≈Ñstwa w PostgreSQL izolujƒÖcy dane u≈ºytkownik√≥w
- **FTS (Full-Text Search)**: Pe≈Çnotekstowe wyszukiwanie w PostgreSQL
- **GIN Index**: Generalized Inverted Index, typ indeksu dla FTS
- **Spaced Repetition**: Algorytm powt√≥rek oparty na krzywej zapominania
- **Mock Mode**: Tryb symulacji API (bez rzeczywistych wywo≈Ça≈Ñ do OpenRouter)
- **Exponential Backoff**: Strategia retry z wyk≈Çadniczo rosnƒÖcym op√≥≈∫nieniem

### 11.3 Linki do dokumentacji technicznej

- **Astro Docs**: https://docs.astro.build/
- **React Docs**: https://react.dev/
- **Supabase Docs**: https://supabase.com/docs
- **OpenRouter API**: https://openrouter.ai/docs
- **Vitest**: https://vitest.dev/
- **Playwright**: https://playwright.dev/
- **OWASP Testing Guide**: https://owasp.org/www-project-web-security-testing-guide/
- **WCAG 2.1**: https://www.w3.org/WAI/WCAG21/quickref/

---

## Podsumowanie

Niniejszy plan test√≥w zapewnia kompleksowe pokrycie wszystkich aspekt√≥w aplikacji do generowania fiszek z AI. Szczeg√≥lny nacisk po≈Ço≈ºono na:

1. **Bezpiecze≈Ñstwo** - RLS, autoryzacja, rate limiting, ochrona przed typowymi atakami
2. **Niezawodno≈õƒá** - obs≈Çuga b≈Çƒôd√≥w, retry mechanisms, validacja danych
3. **Wydajno≈õƒá** - szybkie API responses, optymalizacja FTS, load testing
4. **Dostƒôpno≈õƒá** - keyboard navigation, screen reader support, WCAG 2.1 AA
5. **Jako≈õƒá kodu** - wysoki code coverage (>80%), testy jednostkowe i integracyjne

Kluczem do sukcesu jest **systematyczne wykonywanie test√≥w** zgodnie z harmonogramem, **szybkie raportowanie i fixing bug√≥w**, oraz **continuous monitoring** w produkcji. CI/CD pipeline z automatycznymi testami zapewni, ≈ºe ka≈ºda zmiana w kodzie jest walidowana przed merge'em.

Plan ten powinien byƒá **living document** - aktualizowany wraz z rozwojem projektu i pojawianiem siƒô nowych wymaga≈Ñ.

---

**Data utworzenia**: 25 stycznia 2026  
**Wersja**: 1.0  
**Autor**: GitHub Copilot (AI QA Engineer)  
**Status**: Draft - Do zatwierdzenia przez Product Owner i Tech Lead
